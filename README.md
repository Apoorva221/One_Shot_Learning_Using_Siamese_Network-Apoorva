One-shot learning is a classification task in which we use one sample image is used to classify many new samples. One approach to address One Shot learning can be addressed using Siamese Network. A Siamese network is an architecture with two or more neural networks using shared weight, each taking a diﬀerent input, and whose outputs are compared to provide classification. Here in this case, I used Convolutional Neural Network. The term Siamese is derived from siamese twins. In our case, I am going to primarily train and test my Siamese Network on the Omniglot Data set. It is an amalgamation of 1623 drawn characters drawn by hand from 50 different alphabets. For each character, there are 20 examples, every character is drawn by a new person at resolution 105x105. I take two images from this dataset as my input. Two input images (say x1 and x2) are taken through the Convolutional Network to generate a fixed length feature vector for each. Considering that the neural network model is trained correctly, I can make this hypothesis: If the two images that are being input refer to the same character, then the resultant feature vectors should also be similar, incase the two input images belong to the diﬀerent characters, in that case their feature vectors should also be diﬀerent. Hence, the distance metric should give a large diﬀerence in this case. As a result, the similarity score created by the output sigmoid layer should also be varying in these two scenarios. This is the central idea behind the Siamese Networks. Finally, I test our model using diﬀerent loss functions and compare the accuracy achieved by them.
